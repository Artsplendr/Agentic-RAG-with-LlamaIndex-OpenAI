{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dd7c4c87",
      "metadata": {
        "id": "dd7c4c87"
      },
      "source": [
        "# Building an Agent Reasoning Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if a user asks a complex question with multiple steps to be clarified? This project is aimed to implement complete Agent Reasoning Loop, which,  instead of tool calling, is able to reason over tools and multiple steps."
      ],
      "metadata": {
        "id": "jUXWbChTnY6z"
      },
      "id": "jUXWbChTnY6z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "This project is based on the course **\"Building Agentic RAG with Llamaindex\"** by **Deeplearning.AI** and is available at the following [link](https://learn.deeplearning.ai/courses/building-agentic-rag-with-llamaindex/)."
      ],
      "metadata": {
        "id": "xyjLw1G3tnd_"
      },
      "id": "xyjLw1G3tnd_"
    },
    {
      "cell_type": "markdown",
      "id": "357c97c9",
      "metadata": {
        "id": "357c97c9"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NH8irGTCpUn",
        "outputId": "3ba41f08-d4ad-47b5-acdd-92f0486fb27a"
      },
      "id": "6NH8irGTCpUn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"YOUR-PATH-HERE\""
      ],
      "metadata": {
        "id": "KacBErHQg1VK"
      },
      "id": "KacBErHQg1VK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install llama-index llama-index-llms-openai llama-index-embeddings-openai openai pypdf"
      ],
      "metadata": {
        "id": "2gUt0H5LH55X"
      },
      "id": "2gUt0H5LH55X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kayYqIZWHZib",
        "outputId": "673927e9-e78c-4c35-a012-1105437bf9b7"
      },
      "id": "kayYqIZWHZib",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llama-index                             0.12.19\n",
            "llama-index-agent-openai                0.4.6\n",
            "llama-index-cli                         0.4.0\n",
            "llama-index-core                        0.12.19\n",
            "llama-index-embeddings-openai           0.3.1\n",
            "llama-index-indices-managed-llama-cloud 0.6.7\n",
            "llama-index-llms-openai                 0.3.20\n",
            "llama-index-multi-modal-llms-openai     0.4.3\n",
            "llama-index-program-openai              0.3.1\n",
            "llama-index-question-gen-openai         0.3.0\n",
            "llama-index-readers-file                0.4.5\n",
            "llama-index-readers-llama-parse         0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    SummaryIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        "    Settings\n",
        ")\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.query_engine import RouterQueryEngine\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core.tools import FunctionTool, QueryEngineTool\n",
        "from llama_index.core.vector_stores import MetadataFilters, FilterCondition\n",
        "from typing import List, Optional\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "vgXLHIhIMiQC"
      },
      "id": "vgXLHIhIMiQC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5f4f4a-5890-451c-8869-24606ef9f396",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "ab5f4f4a-5890-451c-8869-24606ef9f396"
      },
      "outputs": [],
      "source": [
        "# Set OpenAI API key\n",
        "import openai\n",
        "\n",
        "openai.api_key = 'YOUR-OPENAI-API-KEY-HERE'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "KnAhNgOUZnN0"
      },
      "id": "KnAhNgOUZnN0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data"
      ],
      "metadata": {
        "id": "nvoOWE9fQFBe"
      },
      "id": "nvoOWE9fQFBe"
    },
    {
      "cell_type": "code",
      "source": [
        "#the pdf file is available here\n",
        "#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
      ],
      "metadata": {
        "id": "EIg9CmnSQDpo"
      },
      "id": "EIg9CmnSQDpo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the Query Tools"
      ],
      "metadata": {
        "id": "I3FybS5_QYIj"
      },
      "id": "I3FybS5_QYIj"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_doc_tools(\n",
        "    file_path: str,\n",
        "    name: str,\n",
        ") -> str:\n",
        "    \"\"\"Get vector query and summary query tools from a document.\"\"\"\n",
        "\n",
        "    # load documents\n",
        "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
        "    splitter = SentenceSplitter(chunk_size=1024)\n",
        "    nodes = splitter.get_nodes_from_documents(documents)\n",
        "    vector_index = VectorStoreIndex(nodes)\n",
        "\n",
        "    def vector_query(\n",
        "        query: str,\n",
        "        page_numbers: Optional[List[str]] = None\n",
        "    ) -> str:\n",
        "        \"\"\"Use to answer questions over the MetaGPT paper.\n",
        "\n",
        "        Useful if you have specific questions over the MetaGPT paper.\n",
        "        Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
        "\n",
        "        Args:\n",
        "            query (str): the string query to be embedded.\n",
        "            page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE\n",
        "                if we want to perform a vector search\n",
        "                over all pages. Otherwise, filter by the set of specified pages.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        page_numbers = page_numbers or []\n",
        "        metadata_dicts = [\n",
        "            {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
        "        ]\n",
        "\n",
        "        query_engine = vector_index.as_query_engine(\n",
        "            similarity_top_k=2,\n",
        "            filters=MetadataFilters.from_dicts(\n",
        "                metadata_dicts,\n",
        "                condition=FilterCondition.OR\n",
        "            )\n",
        "        )\n",
        "        response = query_engine.query(query)\n",
        "        return response\n",
        "\n",
        "\n",
        "    vector_query_tool = FunctionTool.from_defaults(\n",
        "        name=f\"vector_tool_{name}\",\n",
        "        fn=vector_query\n",
        "    )\n",
        "\n",
        "    summary_index = SummaryIndex(nodes)\n",
        "    summary_query_engine = summary_index.as_query_engine(\n",
        "        response_mode=\"tree_summarize\",\n",
        "        use_async=True,\n",
        "    )\n",
        "    summary_tool = QueryEngineTool.from_defaults(\n",
        "        name=f\"summary_tool_{name}\",\n",
        "        query_engine=summary_query_engine,\n",
        "        description=(\n",
        "            \"Use ONLY IF you want to get a holistic summary of MetaGPT. \"\n",
        "            \"Do NOT use if you have specific questions over MetaGPT.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return vector_query_tool, summary_tool"
      ],
      "metadata": {
        "id": "gR2k-t1GQDse"
      },
      "id": "gR2k-t1GQDse",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_tool, summary_tool = get_doc_tools(\"metagpt.pdf\", \"metagpt\")"
      ],
      "metadata": {
        "id": "E1nxYqIrQDvr"
      },
      "id": "E1nxYqIrQDvr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Function Calling Agent"
      ],
      "metadata": {
        "id": "UYzAi7KBTJxv"
      },
      "id": "UYzAi7KBTJxv"
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "rb8JXcXUQDyB"
      },
      "id": "rb8JXcXUQDyB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### High-Level Agent Architecture\n",
        "\n",
        "Based on LlamaIndex [documentation](https://docs.llamaindex.ai/en/stable/examples/agent/agent_runner/agent_runner/), **\"agents\"** are composed of **AgentRunner** objects that interact with **AgentWorkers**. AgentRunners are orchestrators that store state (including conversational memory), create and maintain tasks, run steps through each task, and offer the user-facing, high-level interface for users to interact with.\n",
        "\n",
        "AgentWorkers control the step-wise execution of a Task. Given an input step, an agent worker is responsible for generating the next step. They can be initialized with parameters and act upon state passed down from the Task/TaskStep objects, but do not inherently store state themselves. The outer AgentRunner is responsible for calling an AgentWorker and collecting/aggregating the results.\"\n"
      ],
      "metadata": {
        "id": "PLA7qivVWDQD"
      },
      "id": "PLA7qivVWDQD"
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [vector_tool, summary_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ],
      "metadata": {
        "id": "SuqLHsFVQD0I"
      },
      "id": "SuqLHsFVQD0I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.query(\n",
        "    \"Tell me about the agent roles in MetaGPT, \"\n",
        "    \"and then how they communicate with each other.\"\n",
        ")"
      ],
      "metadata": {
        "id": "2x5uCcWnQD28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd441f8-ba31-4e85-fa82-167e1ae090ae"
      },
      "id": "2x5uCcWnQD28",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_metagpt with args: {\"input\": \"agent roles in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "In MetaGPT, the agent roles include the Product Manager responsible for creating the Product Requirement Document and analyzing requirements, the Architect who designs the system architecture and technical specifications, the Project Manager who breaks down the project into tasks and assigns them to Engineers, the Engineers who develop the code based on specifications, and the QA Engineer who reviews the code, creates unit tests, and ensures software quality. Each agent has a specialized role contributing to the collaborative software development process in MetaGPT.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_metagpt with args: {\"input\": \"communication between agent roles in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "The communication between agent roles in MetaGPT is structured and efficient, facilitated through a global message pool and a subscription mechanism. This system helps address the challenge of information overload by streamlining communication and ensuring efficiency. The global message pool allows agents to exchange information effectively, while the subscription mechanism filters out irrelevant contexts, enhancing the relevance and utility of the shared information. This structured communication approach is particularly crucial in software design scenarios and standard operating procedures where effective collaboration and information sharing are essential for successful project outcomes.\n",
            "=== LLM Response ===\n",
            "In MetaGPT, the agent roles include the Product Manager, Architect, Project Manager, Engineers, and QA Engineer. Each agent has a specialized role contributing to the collaborative software development process. \n",
            "\n",
            "The communication between these agent roles is structured and efficient, facilitated through a global message pool and a subscription mechanism. This system helps streamline communication and ensure efficiency by allowing agents to exchange information effectively and filter out irrelevant contexts. This structured communication approach is crucial for effective collaboration and information sharing in software design scenarios.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.source_nodes[0].get_content(metadata_mode=\"all\"))"
      ],
      "metadata": {
        "id": "6jKEPZQiQD5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31d7664-1ff7-4021-ac3c-9275f899dc1a"
      },
      "id": "6jKEPZQiQD5R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_label: 1\n",
            "file_name: metagpt.pdf\n",
            "file_path: metagpt.pdf\n",
            "file_type: application/pdf\n",
            "file_size: 16911937\n",
            "creation_date: 2025-02-18\n",
            "last_modified_date: 2025-02-14\n",
            "\n",
            "Preprint\n",
            "METAGPT: M ETA PROGRAMMING FOR A\n",
            "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
            "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
            "Ceyao Zhang4, Jinlin Wang1, Zili Wang, Steven Ka Shing Yau5, Zijuan Lin4,\n",
            "Liyang Zhou6, Chenyu Ran1, Lingfeng Xiao1,7, Chenglin Wu1†, J¨urgen Schmidhuber2,8\n",
            "1DeepWisdom, 2AI Initiative, King Abdullah University of Science and Technology,\n",
            "3Xiamen University, 4The Chinese University of Hong Kong, Shenzhen,\n",
            "5Nanjing University, 6University of Pennsylvania,\n",
            "7University of California, Berkeley, 8The Swiss AI Lab IDSIA/USI/SUPSI\n",
            "ABSTRACT\n",
            "Remarkable progress has been made on automated problem solving through so-\n",
            "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
            "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
            "complex tasks, however, are complicated through logic inconsistencies due to\n",
            "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
            "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
            "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
            "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
            "streamlined workflows, thus allowing agents with human-like domain expertise\n",
            "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
            "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
            "complex tasks into subtasks involving many agents working together. On col-\n",
            "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
            "solutions than previous chat-based multi-agent systems. Our project can be found\n",
            "at https://github.com/geekan/MetaGPT.\n",
            "1 I NTRODUCTION\n",
            "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
            "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
            "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
            "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
            "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
            "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
            "et al., 2023; Qian et al., 2023).\n",
            "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
            "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
            "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
            "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
            "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
            "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
            "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
            "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
            "(PRDs) using a standardized structure, to guide the developmental process.\n",
            "Inspired by such ideas, we design a promising GPT -based Meta-Programming framework called\n",
            "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
            "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
            "∗These authors contributed equally to this work.\n",
            "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The agents can maintain the conversation history over time\n",
        "response = agent.chat(\n",
        "    \"Tell me about the evaluation datasets used.\"\n",
        ")"
      ],
      "metadata": {
        "id": "9PpQQPTmQD9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b6aaa4-c86c-440e-dd80-e597a6aca94b"
      },
      "id": "9PpQQPTmQD9V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me about the evaluation datasets used.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_metagpt with args: {\"input\": \"evaluation datasets used in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset.\n",
            "=== LLM Response ===\n",
            "The evaluation datasets used in MetaGPT include HumanEval, MBPP, and a self-generated SoftwareDev dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"Tell me the results over one of the above datasets.\")"
      ],
      "metadata": {
        "id": "vr6XYmjwQD-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b473192-67c4-42ff-b0ec-fc42153abb65"
      },
      "id": "vr6XYmjwQD-8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me the results over one of the above datasets.\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool_metagpt with args: {\"query\": \"results over HumanEval dataset\", \"page_numbers\": null}\n",
            "=== Function Output ===\n",
            "MetaGPT achieved a pass rate of 85.9% and 87.7% over the HumanEval dataset.\n",
            "=== LLM Response ===\n",
            "MetaGPT achieved a pass rate of 85.9% and 87.7% over the HumanEval dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to LlamaIndex documentation, there are the following benefits of agent control:\n",
        "* **Decoupling of Task Creation and Execution**: Users gain the flexibility to schedule task execution according to their needs.\n",
        "* **Enhanced Debuggabilty**: Offers deeper insights into each step of the execution process, improving troubleshooting capabilities.\n",
        "* **Steerability**: Allows users to directly modify intermediate steps and incorporate human feedback for refined control."
      ],
      "metadata": {
        "id": "k3Wk5FrNbPPm"
      },
      "id": "k3Wk5FrNbPPm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lower-Level: Debuggability and Control"
      ],
      "metadata": {
        "id": "IXvn_7fCdEPM"
      },
      "id": "IXvn_7fCdEPM"
    },
    {
      "cell_type": "code",
      "source": [
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    [vector_tool, summary_tool],\n",
        "    llm=llm,\n",
        "    verbose=True\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ],
      "metadata": {
        "id": "4bNazBKqZZJH"
      },
      "id": "4bNazBKqZZJH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = agent.create_task(\n",
        "    \"Tell me about the agent roles in MetaGPT, \"\n",
        "    \"and then how they communicate with each other.\"\n",
        ")"
      ],
      "metadata": {
        "id": "Dx1kxYhJZZL6"
      },
      "id": "Dx1kxYhJZZL6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step_output = agent.run_step(task.task_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzTXKWcZZZO_",
        "outputId": "21dedbee-f2aa-4ca7-fe69-d0a9ed31c2a2"
      },
      "id": "hzTXKWcZZZO_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me about the agent roles in MetaGPT, and then how they communicate with each other.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_metagpt with args: {\"input\": \"agent roles in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "The agent roles in MetaGPT include the Product Manager, who is responsible for creating the Product Requirement Document and analyzing user stories and competitive analysis; the Architect, who designs the system architecture; the Project Manager, who breaks down tasks and assigns them to Engineers; the Engineers, who develop the code based on specifications; and the QA Engineer, who reviews the code, generates unit tests, and ensures software quality. Each agent has a specific role in the collaborative workflow to contribute to the success of the project.\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_metagpt with args: {\"input\": \"how agents communicate with each other in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "Agents in MetaGPT communicate with each other through structured communication interfaces, a publish-subscribe mechanism, a shared message pool, and a subscription mechanism. This approach allows agents to exchange structured messages transparently, publish messages in the shared pool, access messages from other agents based on their profiles, and subscribe to specific information based on their roles. This structured communication system enhances collaboration, minimizes information overload, streamlines communication, ensures efficiency by filtering out irrelevant contexts, and helps enhance the relevance and utility of the information exchanged among agents in MetaGPT.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completed_steps = agent.get_completed_steps(task.task_id)\n",
        "print(f\"Num completed for task {task.task_id}: {len(completed_steps)}\")\n",
        "print(completed_steps[0].output.sources[0].raw_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSEMz0f1ZZRk",
        "outputId": "66cda027-651b-4d5c-f0ac-e9f643471656"
      },
      "id": "nSEMz0f1ZZRk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num completed for task 24c88674-90be-4b3b-8c65-6a48758f9e85: 1\n",
            "The agent roles in MetaGPT include the Product Manager, who is responsible for creating the Product Requirement Document and analyzing user stories and competitive analysis; the Architect, who designs the system architecture; the Project Manager, who breaks down tasks and assigns them to Engineers; the Engineers, who develop the code based on specifications; and the QA Engineer, who reviews the code, generates unit tests, and ensures software quality. Each agent has a specific role in the collaborative workflow to contribute to the success of the project.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upcoming_steps = agent.get_upcoming_steps(task.task_id)\n",
        "print(f\"Num upcoming steps for task {task.task_id}: {len(upcoming_steps)}\")\n",
        "upcoming_steps[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2WaNLyYZZUK",
        "outputId": "e7342629-1d8e-48ee-b2fa-20ac1c8b148b"
      },
      "id": "z2WaNLyYZZUK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num upcoming steps for task 24c88674-90be-4b3b-8c65-6a48758f9e85: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskStep(task_id='24c88674-90be-4b3b-8c65-6a48758f9e85', step_id='aa9c72e1-b31c-4cac-af1c-f82e76f572a3', input=None, step_state={}, next_steps={}, prev_steps={}, is_ready=True)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_output = agent.run_step(\n",
        "    task.task_id, input=\"What about how agents share information?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67F6wMGFZZW6",
        "outputId": "4935e3b3-59c0-4343-e51d-e134220f9c3b"
      },
      "id": "67F6wMGFZZW6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: What about how agents share information?\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_metagpt with args: {\"input\": \"how agents share information in MetaGPT\"}\n",
            "=== Function Output ===\n",
            "Agents in MetaGPT share information through a structured communication protocol that includes a shared message pool and a publish-subscribe mechanism. This allows them to exchange messages directly and subscribe to relevant messages based on their profiles. The shared message pool and subscription mechanism enhance communication efficiency by providing a centralized platform for information exchange and ensuring that agents receive only task-related information, thus avoiding information overload.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_output = agent.run_step(task.task_id)\n",
        "print(step_output.is_last)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMOaHr2FZZeb",
        "outputId": "c2e94484-aeb2-4d85-ca41-08852abc462d"
      },
      "id": "qMOaHr2FZZeb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== LLM Response ===\n",
            "Agents in MetaGPT share information through a structured communication protocol that includes a shared message pool and a publish-subscribe mechanism. This allows them to exchange messages directly and subscribe to relevant messages based on their profiles. The shared message pool and subscription mechanism enhance communication efficiency by providing a centralized platform for information exchange and ensuring that agents receive only task-related information, thus avoiding information overload.\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final response\n",
        "response = agent.finalize_response(task.task_id)\n",
        "\n",
        "# Extract the response text\n",
        "response_text = str(response) if isinstance(response, str) else response.response\n",
        "\n",
        "# Wrap text to a readable width\n",
        "wrapped_response = textwrap.fill(response_text, width=80)\n",
        "\n",
        "# Print structured output\n",
        "print(\"=\" * 80)\n",
        "print(\"**Generated Final Response:**\\n\")\n",
        "print(wrapped_response)\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfYeYrU-ZZip",
        "outputId": "104da4b5-127a-4188-c5eb-d797b22d7212"
      },
      "id": "kfYeYrU-ZZip",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "**Generated Final Response:**\n",
            "\n",
            "Agents in MetaGPT share information through a structured communication protocol\n",
            "that includes a shared message pool and a publish-subscribe mechanism. This\n",
            "allows them to exchange messages directly and subscribe to relevant messages\n",
            "based on their profiles. The shared message pool and subscription mechanism\n",
            "enhance communication efficiency by providing a centralized platform for\n",
            "information exchange and ensuring that agents receive only task-related\n",
            "information, thus avoiding information overload.\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}